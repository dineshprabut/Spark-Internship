{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Social_Distance_Detection.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLjSO7tsZyv7"
      },
      "source": [
        "#Setting up the variable values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeneA9qNZ6NF"
      },
      "source": [
        "MIN_CONF=0.3\n",
        "NMS_THRESH=0.3\n",
        "\n",
        "MIN_DISTANCE=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6zv18UUantj"
      },
      "source": [
        "#Creating the people detection function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dt4XJNPam4r"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def detect_people(frame,net,ln,personIdx=0):\n",
        "  (H,W)=frame.shape[:2]\n",
        "  results=[]\n",
        "\n",
        "  blob=cv2.dnn.blobFromImage(frame,1/255.0,(416,416),swapRB=True,crop=False)\n",
        "  net.setInput(blob)\n",
        "  layerOutputs=net.forward(ln)\n",
        "\n",
        "  boxes=[]\n",
        "  centroids=[]\n",
        "  confidences=[]\n",
        "\n",
        "  for output in layerOutputs:\n",
        "    for detection in output:\n",
        "      scores=detection[5:]\n",
        "      classID=np.argmax(scores)\n",
        "      confidence=scores[classID]\n",
        "\n",
        "      if classID == personIdx and confidence > MIN_CONF:\n",
        "        box=detection[0:4] * np.array([W,H,W,H])\n",
        "        (centerX,centerY,width,height)=box.astype(\"int\")\n",
        "\n",
        "        x=int(centerX - (width/2))\n",
        "        y=int(centerY - (height/2))\n",
        "\n",
        "        boxes.append([x,y,int(width),int(height)])\n",
        "        centroids.append((centerX,centerY))\n",
        "        confidences.append(float(confidence))\n",
        "  idxs=cv2.dnn.NMSBoxes(boxes,confidences,MIN_CONF,NMS_THRESH)\n",
        "  \n",
        "  if len(idxs)>0:\n",
        "    for i in idxs.flatten():\n",
        "      (x,y)=(boxes[i][0],boxes[i][1])\n",
        "      (w,h)=(boxes[i][2],boxes[i][3])\n",
        "\n",
        "      r=(confidences[i],(x,y,x+w,y+h),centroids[i])\n",
        "      results.append(r)\n",
        "  return results\n",
        "      \n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxUihloJevm3"
      },
      "source": [
        "#Grab frames from video and make prediction measuring distances of detected people"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ0ufG4Re7aA"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from scipy.spatial import distance as dist\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "ap=argparse.ArgumentParser()\n",
        "ap.add_argument(\"-i\",\"--input\",type=str,default=\"\",help=\"path to (optional) input video file\")\n",
        "ap.add_argument(\"-o\",\"--output\",type=str,default=\"\",help=\"path to (optional) output video file\")\n",
        "ap.add_argument(\"-d\",\"--display\",type=int,default=1,help=\"whether or not output frame should be displayed\")\n",
        "args=vars(ap.parse_args([\"--input\",\"/content/drive/MyDrive/social-distance-detector/pedestrians.mp4\", \"--output\",\"my_output.avi\",\"--display\",\"1\"]))\n",
        "\n",
        "labelsPath=os.path.sep.join([\"/content/drive/MyDrive/social-distance-detector/yolo-coco/coco.names\"])\n",
        "LABELS=open(labelsPath).read().strip().split(\"\\n\")\n",
        "\n",
        "weightsPath=os.path.sep.join([\"/content/drive/MyDrive/social-distance-detector/yolo-coco/yolov3.weights\"])\n",
        "configPath=os.path.sep.join([\"/content/drive/MyDrive/social-distance-detector/yolo-coco/yolov3.cfg\"])\n",
        "\n",
        "print(\"[INFO] loading YOLO from disk\")\n",
        "net=cv2.dnn.readNetFromDarknet(configPath,weightsPath)\n",
        "\n",
        "ln=net.getLayerNames()\n",
        "ln=[ln[ i[0] -1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "print(\"[INFO] accessing video stream...\")\n",
        "vs=cv2.VideoCapture(args[\"input\"] if args[\"input\"] else 0)\n",
        "writer=None\n",
        "\n",
        "while True:\n",
        "    (grabbed,frame)=vs.read()\n",
        "    \n",
        "    if not grabbed:\n",
        "      break\n",
        "\n",
        "    frame=imutils.resize(frame,width=700)\n",
        "    results=detect_people(frame,net,ln,personIdx=LABELS.index(\"person\"))\n",
        "    violate=set()\n",
        "\n",
        "    if len(results)>=2:\n",
        "      centroids=np.array([r[2] for r in results ])\n",
        "      D=dist.cdist(centroids,centroids,metric=\"euclidean\")\n",
        "\n",
        "      for i in range(0,D.shape[0]):\n",
        "        for j in range(i+1,D.shape[1]):\n",
        "          if D[i,j]<MIN_DISTANCE:\n",
        "            violate.add(i)\n",
        "            violate.add(j)\n",
        "    for (i,(prob,bbox,centroid)) in enumerate(results):\n",
        "      (startX,startY,endX,endY)=bbox\n",
        "      (cX,cY)=centroid\n",
        "      color=(0,255,0)\n",
        "\n",
        "      if i in violate:\n",
        "        color=(0,0,255)\n",
        "      \n",
        "      cv2.rectangle(frame,(startX,startY),(endX,endY),color,2)\n",
        "      cv2.circle(frame,(cX,cY),5,color,1)\n",
        "    \n",
        "    text=\"social distancing violation:{}\".format(len(violate))\n",
        "    cv2.putText(frame,text,(10,frame.shape[0]-25),cv2.FONT_HERSHEY_SIMPLEX,0.85,(0,0,255),3)\n",
        "    if args[\"display\"] >0:\n",
        "      cv2_imshow(frame)\n",
        "      key=cv2.waitKey(1)&0xFF\n",
        "      if key ==ord('q'):\n",
        "        break\n",
        "    if args[\"output\"] !=\"\" and writer is None:\n",
        "      fourcc=cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "      writer=cv2.VideoWriter(args[\"output\"],fourcc,25,(frame.shape[1],frame.shape[0]),True) \n",
        "    if writer is not None:\n",
        "      writer.write(frame)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH6METkjpqyp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}